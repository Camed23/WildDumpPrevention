"""
Classifier - Module de classification binaire des poubelles pleines/vides

LOGIQUE G√âN√âRALE :
- S√©parer scoring (rules_engine) et classification (ce module)
- Utiliser des seuils configurables pour transformer les scores en pr√©dictions
- Classification binaire forc√©e : "plein" ou "vide" uniquement (plus d'"inconnu")
- Fournir des m√©triques de confiance pour √©valuer la qualit√© des pr√©dictions

ARCHITECTURE :
1. BinClassifier : Classe principale qui utilise RulesEngine + d√©cision binaire
2. test_classifier() : Fonction pour √©valuer les performances sur un dataset
3. Gestion des erreurs et analyse pour am√©lioration continue
"""

# backend/services/classifier.py

import json
import backend.config as config
from backend.services.feature_extractor import ImageFeatures
from backend.services.rules_engine import RulesEngine
from collections import Counter

# Configuration
#CACHE_PATH = "cache/images_metadata_labeled.json"
CACHE_PATH = config.CACHE_PATH  # Utiliser la configuration une fois le projet termin√©


class BinClassifier:
    """
    Classificateur principal pour d√©terminer si une poubelle est pleine ou vide (classification binaire)
    
    LOGIQUE DE CONCEPTION :
    1. Utilise un RulesEngine pour obtenir un score [-1, +1]
    2. Applique une d√©cision binaire simple : score >= 0 ‚Üí "plein", score < 0 ‚Üí "vide"
    3. Calcule une confiance bas√©e sur l'amplitude du score et la coh√©rence des r√®gles
    4. Permet l'ajustement dynamique des seuils
    5. **NOUVEAU**: Plus de cat√©gorie "inconnu" - toujours une d√©cision ferme
    
    AVANTAGES :
    - S√©paration claire entre scoring et classification
    - D√©cision binaire forc√©e pour √©viter l'ind√©cision
    - M√©triques de confiance pour √©valuer la fiabilit√©
    - Facilit√© d'ajustement des param√®tres selon le contexte d'usage
    - Exploitation optimale des r√®gles avanc√©es
    """
    def __init__(self, rules_engine=None, thresholds=None, high_precision=False):
        """
        Initialise le classificateur
        
        Args:
            rules_engine (RulesEngine): Moteur de r√®gles personnalis√© (optionnel)
            thresholds (dict): Seuils de classification personnalis√©s (optionnel)
            high_precision (bool): Active le mode haute pr√©cision (plus strict, plus de r√®gles)
            
        LOGIQUE DES SEUILS :
        - full_min : Score minimum pour √™tre s√ªr que c'est "plein"
        - empty_max : Score maximum pour √™tre s√ªr que c'est "vide"
        - Zone d'incertitude : entre empty_max et full_min
        - confidence_min : Seuil de confiance en dessous duquel on force "inconnu"
        - rules_count_min : Nombre minimum de r√®gles actives pour une confiance √©lev√©e
        - advanced_rules_bonus : Bonus de confiance si des r√®gles avanc√©es sont actives
        """
        self.rules_engine = rules_engine or RulesEngine()
        self.high_precision = high_precision
        
        # Seuils recalibr√©s pour √©quilibrer les pr√©dictions entre "plein" et "vide"
        base_thresholds = {
            'full_min': 0.20 if high_precision else 0.15,      # ABAISS√â pour faciliter la d√©tection "plein"
            'empty_max': -0.2 if high_precision else -0.15,    # RENDU PLUS STRICT pour "vide" 
            'confidence_min': 0.15 if high_precision else 0.12, # ABAISS√â pour r√©duire les "inconnu"
            'rules_count_min': 5 if high_precision else 4,      # L√©g√®rement r√©duit
            'advanced_rules_bonus': 0.1,                        # AUGMENT√â pour valoriser les r√®gles avanc√©es
            'negative_rules_min': 3 if high_precision else 2    # Inchang√©
        }
        
        # Utiliser les seuils fournis ou les valeurs par d√©faut
        self.thresholds = thresholds or base_thresholds
        
        # Liste des r√®gles avanc√©es pour le bonus de confiance
        self.advanced_rules = [
            'texture_entropy_high', 'texture_entropy_low',
            'color_complexity_high', 'color_complexity_low',
            'brightness_variance_high', 'brightness_variance_low',
            'spatial_frequency_high', 'spatial_frequency_low',
            'fill_ratio_advanced_high', 'fill_ratio_advanced_low',
            'red_blue_ratio_high', 'saturation_high',
            'corner_variance_high', 'vertical_fill_high',
            'irregular_shapes_high', 'symmetry_high',
            'background_uniformity_high', 'center_emptiness_high',
            'vertical_fill_low', 'perspective_lines_visible'
        ]
        
    def classify(self, features):
        """
        Classifie une image en fonction de ses features extraites
        
        LOGIQUE DE CLASSIFICATION AM√âLIOR√âE :
        1. Obtenir un score normalis√© [-1, +1] via le RulesEngine
        2. Calculer le ratio de r√®gles positives vs n√©gatives
        3. V√©rifier si le score et le ratio de r√®gles sont coh√©rents
        4. Appliquer une logique plus stricte pour la classe "plein"
        5. Calculer une confiance en tenant compte du ratio de r√®gles
        6. Filtrer les pr√©dictions √† faible confiance
        
        STRAT√âGIE DE D√âCISION BINAIRE (SANS "INCONNU") :
        - "plein" : score >= 0 (positif ou neutre)
        - "vide" : score < 0 (n√©gatif)
        - Confiance calcul√©e selon l'amplitude du score et la coh√©rence des r√®gles
        
        Args:
            features (dict): Features extraites de l'image (area_ratio, contrast, etc.)
            
        Returns:
            dict: {
                'prediction': str,          # 'plein' ou 'vide' uniquement
                'confidence': float,        # Confiance [0, 1] dans la pr√©diction
                'score': float,             # Score brut du RulesEngine [-1, +1]
                'details': dict,            # D√©tails de l'√©valuation (r√®gles actives, etc.)
                'advanced_rules': list,     # Liste des r√®gles avanc√©es actives
                'positive_rules_count': int, # Nombre de r√®gles positives activ√©es
                'negative_rules_count': int, # Nombre de r√®gles n√©gatives activ√©es
                'rules_ratio': float        # Ratio r√®gles positives/n√©gatives
            }
        """
        # √âtape 1 : √âvaluation avec le moteur de r√®gles
        evaluation = self.rules_engine.evaluate(features)
        score = evaluation['score']  # Score normalis√© [-1, +1]
        active_rules = evaluation.get('active_rules', [])
        raw_score = evaluation.get('raw_score', 0)
        
        # √âtape 2 : Analyse des r√®gles actives par type
        # Liste des r√®gles n√©gatives (vide) connues - rendue plus pr√©cise et exhaustive
        negative_rule_prefixes = (
            'area_ratio_low', 'hue_std_low', 'contrast_iqr_low', 'edge_density_high', 
            'mean_brightness_high', 'texture_entropy_low', 'color_complexity_low', 
            'brightness_variance_low', 'spatial_frequency_low', 'fill_ratio_advanced_low', 
            'spatial_frequency_very_low', 'file_size_low', 'edge_coherence_high', 
            'symmetry_high', 'background_uniformity_high', 'center_emptiness_high', 
            'vertical_fill_low', 'perspective_lines_visible', 'edge_density_low', 
            'very_empty_center', 'structural_symmetry_with_edges', 'uniform_brightness',
            'corner_variance_low'
        )
        
        # Compter les r√®gles n√©gatives et positives de mani√®re plus robuste
        negative_rules = [rule for rule in active_rules if any(rule.startswith(prefix) for prefix in negative_rule_prefixes)]
        positive_rules = [rule for rule in active_rules if rule not in negative_rules]
        
        # Calculer le ratio de r√®gles (√©viter division par z√©ro)
        pos_count = len(positive_rules)
        neg_count = len(negative_rules)
        rules_ratio = pos_count / max(1, neg_count)
        
        # √âtape 3 : Classification binaire forc√©e (plus de label "inconnu")
        # Logique simplifi√©e : d√©cision bas√©e principalement sur le score
        if score >= 0:
            # Score positif ou neutre ‚Üí tendance "plein"
            prediction = "plein"
            # Confiance bas√©e sur le score et renforc√©e par le ratio de r√®gles
            base_confidence = min(abs(score) * 1.5 + 0.3, 1.0)  # Score minimum de confiance : 0.3
            rules_bonus = min(rules_ratio / 4.0, 0.3) if rules_ratio >= 1.0 else 0  # Bonus si ratio favorable
            confidence = min(base_confidence + rules_bonus, 1.0)
            
        else:
            # Score n√©gatif ‚Üí tendance "vide"  
            prediction = "vide"
            # Confiance bas√©e sur l'amplitude du score n√©gatif et le nombre de r√®gles n√©gatives
            base_confidence = min(abs(score) * 1.5 + 0.3, 1.0)  # Score minimum de confiance : 0.3
            neg_bonus = min(neg_count / 5.0, 0.3) if neg_count >= 2 else 0  # Bonus si suffisamment de r√®gles n√©gatives
            confidence = min(base_confidence + neg_bonus, 1.0)
            
        # √âtape 4 : Ajustement de confiance bas√© sur les r√®gles avanc√©es
        # Identifier les r√®gles avanc√©es actives
        advanced_active = [rule for rule in active_rules if rule in self.advanced_rules]
        # √âtape 4 : Ajustements bas√©s sur les r√®gles avanc√©es sp√©cifiques
        if len(advanced_active) > 0:
                # R√®gles sp√©cifiques √† la classe pleine
                if prediction == "plein":
                    # V√©rifier la pr√©sence de r√®gles avanc√©es vraiment discriminantes pour "plein"
                    critical_full_rules = ['fill_ratio_advanced_high', 'vertical_fill_high', 'irregular_shapes_high']
                    critical_count = len([r for r in advanced_active if r in critical_full_rules])
                    
                    if critical_count > 0:
                        # Bonus si des r√®gles critiques sont pr√©sentes
                        bonus = min(critical_count / len(critical_full_rules), 1.0) * 0.3
                        confidence = min(confidence + bonus, 1.0)
                    else:
                        # P√©nalit√© si aucune r√®gle critique n'est pr√©sente
                        confidence *= 0.7
                        
                    # V√©rifier qu'il n'y a pas trop de r√®gles contradictoires
                    contradictory_rules = ['symmetry_high', 'background_uniformity_high', 'center_emptiness_high']
                    contradictory_count = len([r for r in advanced_active if r in contradictory_rules])
                    
                    if contradictory_count > 0:
                        # Forte p√©nalit√© si des r√®gles contradictoires sont pr√©sentes
                        confidence *= (1.0 - contradictory_count * 0.2)
                
                # R√®gles sp√©cifiques √† la classe vide
                elif prediction == "vide":
                    # V√©rifier la pr√©sence de r√®gles avanc√©es vraiment discriminantes pour "vide"
                    critical_empty_rules = ['symmetry_high', 'background_uniformity_high', 'center_emptiness_high', 'vertical_fill_low']
                    critical_count = len([r for r in advanced_active if r in critical_empty_rules])
                    
                    if critical_count > 0:
                        # Bonus si des r√®gles critiques sont pr√©sentes
                        bonus = min(critical_count / len(critical_empty_rules), 1.0) * 0.3
                        confidence = min(confidence + bonus, 1.0)
                    else:
                        # P√©nalit√© si aucune r√®gle critique n'est pr√©sente
                        confidence *= 0.7
        
        # √âtape 5 : Malus de confiance si trop peu de r√®gles sont actives au total
        min_total_rules = self.thresholds['rules_count_min']
        if len(active_rules) < min_total_rules:
            confidence *= (len(active_rules) / min_total_rules) * 0.9  # Moins p√©nalisant qu'avant
        
        # Plus de filtrage par confiance minimum ni de v√©rifications suppl√©mentaires
        # qui forceraient vers "inconnu" - on garde toujours la pr√©diction binaire
            
        return {
            'prediction': prediction,
            'confidence': confidence,
            'score': score,
            'details': evaluation,
            'advanced_rules': advanced_active,
            'positive_rules_count': len(positive_rules),
            'negative_rules_count': len(negative_rules)
        }
    
    def set_thresholds(self, full_min=None, empty_max=None, confidence_min=None, 
                      rules_count_min=None, advanced_rules_bonus=None, negative_rules_min=None):
        """
        Ajuste les seuils de classification pour optimiser les performances
        
        UTILIT√â :
        - Adapter le comportement selon le contexte (tol√©rance aux erreurs)
        - Optimiser la pr√©cision apr√®s analyse des r√©sultats
        - Exp√©rimenter avec diff√©rents compromis pr√©cision/rappel
        
        Args:
            full_min (float): Seuil minimum pour "plein" (plus haut = plus strict)
            empty_max (float): Seuil maximum pour "vide" (plus bas = plus strict)  
            confidence_min (float): Confiance minimum requise (plus haut = plus d'"inconnu")
            rules_count_min (int): Nombre minimum de r√®gles actives pour confiance √©lev√©e
            advanced_rules_bonus (float): Bonus de confiance pour les r√®gles avanc√©es
            negative_rules_min (int): Nombre minimum de r√®gles n√©gatives pour classer "vide"
        """
        if full_min is not None:
            self.thresholds['full_min'] = full_min
        if empty_max is not None:
            self.thresholds['empty_max'] = empty_max
        if confidence_min is not None:
            self.thresholds['confidence_min'] = confidence_min
        if rules_count_min is not None:
            self.thresholds['rules_count_min'] = rules_count_min
        if advanced_rules_bonus is not None:
            self.thresholds['advanced_rules_bonus'] = advanced_rules_bonus
        if negative_rules_min is not None:
            self.thresholds['negative_rules_min'] = negative_rules_min
            
    def set_high_precision(self, enabled=True):
        """
        Active ou d√©sactive le mode haute pr√©cision
        
        UTILIT√â :
        - Quand la pr√©cision est critique, utiliser enabled=True
        - Pour maximiser les pr√©dictions d√©finitives, utiliser enabled=False
        
        Args:
            enabled (bool): True pour activer le mode haute pr√©cision
        """
        self.high_precision = enabled
        
        # Ajuster les seuils selon le mode - nettement recalibr√©s
        if enabled:
            self.set_thresholds(
                full_min=0.35,              # Beaucoup plus strict pour "plein"
                empty_max=-0.1,             # Plus permissif pour "vide"
                confidence_min=0.2,         # Confiance minimum augment√©e
                rules_count_min=6,          # Plus de r√®gles requises
                negative_rules_min=3        # Minimum 3 r√®gles n√©gatives pour "vide"
            )
        else:
            self.set_thresholds(
                full_min=0.3,               # Plus strict qu'avant
                empty_max=-0.08,            # Plus permissif qu'avant
                confidence_min=0.15,        # Plus exigeant en confiance
                rules_count_min=4,          # Plus de r√®gles requises
                negative_rules_min=2        # Minimum 2 r√®gles n√©gatives pour "vide"
            )


def test_classifier(cache_path=CACHE_PATH, show_details=False, high_precision=False):
    """
    Fonction de test et d'√©valuation du classifier sur un dataset labellis√©
    
    OBJECTIFS :
    1. Mesurer la pr√©cision globale du syst√®me
    2. Analyser la r√©partition des pr√©dictions (plein/vide uniquement)
    3. Identifier les erreurs pour am√©liorer les r√®gles
    4. Calculer des m√©triques de performance (confiance, scores)
    5. Analyser l'impact des r√®gles avanc√©es et le ratio r√®gles positives/n√©gatives
    
    LOGIQUE D'ANALYSE :
    - Comparer pr√©dictions vs labels r√©els
    - Tracker les r√®gles impliqu√©es dans les erreurs
    - Calculer pr√©cision binaire directe (toutes les pr√©dictions sont d√©finitives)
    - Statistiques des scores pour validation du syst√®me
    - Analyse sp√©cifique des r√®gles avanc√©es et des ratios positif/n√©gatif
    
    Args:
        cache_path (str): Chemin vers le fichier JSON des images labellis√©es
        show_details (bool): Afficher les d√©tails des r√®gles pour debug
        high_precision (bool): Utiliser le mode haute pr√©cision
        
    Returns:
        tuple: (classifier, accuracy) pour usage programmatique
    """
    # Initialisation du classifier avec param√®tres recalibr√©s
    classifier = BinClassifier(high_precision=high_precision)
    
    # Chargement du dataset labellis√© depuis le cache JSON
    with open(cache_path, "r", encoding="utf-8") as f:
        images = json.load(f)

    # Initialisation des m√©triques de performance
    total = len(images)                                          # Nombre total d'images
    correct = 0                                                  # Pr√©dictions correctes
    predictions_count = {"plein": 0, "vide": 0}   # R√©partition des pr√©dictions (plus d'"inconnu")
    scores = []                                                  # Scores pour analyse statistique
    confidences = []                                             # Niveaux de confiance
    errors_analysis = []                                         # Analyse d√©taill√©e des erreurs
    advanced_rules_usage = Counter()                             # Compteur des r√®gles avanc√©es
    advanced_rules_success = Counter()                           # R√®gles avanc√©es dans les pr√©dictions correctes
    
    # Nouvelles m√©triques pour analyse des r√®gles positives/n√©gatives
    positive_rules_avg = {"plein": [], "vide": []}  # R√®gles positives par classe (plus d'"inconnu")
    negative_rules_avg = {"plein": [], "vide": []}  # R√®gles n√©gatives par classe (plus d'"inconnu")

    precision_mode = "HAUTE PR√âCISION" if high_precision else "STANDARD"
    print(f"=== TEST DU CLASSIFIER RECALIBR√â (MODE {precision_mode}) ===\n")
    
    # Boucle principale : tester chaque image du dataset
    for i, img in enumerate(images):
        # R√©cup√©ration du label attendu (v√©rit√© terrain)
        annotation = img.get("annotation", [{}])[0]
        true_label = annotation.get("label", "inconnu")

        # Extraction des features visuelles de l'image
        feats = ImageFeatures(img).extract_all_features()
        
        # Classification avec notre syst√®me
        result = classifier.classify(feats)
        predicted = result['prediction']    # Classe pr√©dite
        confidence = result['confidence']   # Confiance [0, 1]
        score = result['score']            # Score brut [-1, +1]
        advanced_rules = result.get('advanced_rules', [])  # R√®gles avanc√©es utilis√©es
        
        # Mise √† jour des statistiques globales
        predictions_count[predicted] += 1
        scores.append(score)
        confidences.append(confidence)
        
        # Mise √† jour du compteur de r√®gles avanc√©es
        for rule in advanced_rules:
            advanced_rules_usage[rule] += 1
            if predicted == true_label:
                advanced_rules_success[rule] += 1
        
        # Collecte des statistiques sur les r√®gles positives/n√©gatives
        pos_count = result.get('positive_rules_count', 0)
        neg_count = result.get('negative_rules_count', 0)
        positive_rules_avg[predicted].append(pos_count)
        negative_rules_avg[predicted].append(neg_count)
        
        # Affichage du r√©sultat pour suivi en temps r√©el avec ratio positif/n√©gatif
        status = "‚úì" if predicted == true_label else "‚úó"  # Symbole visuel pour rapidit√©
        img_name = img.get('name_image', '')[:25]          # Nom tronqu√© pour lisibilit√©
        advanced_count = len(advanced_rules)
        ratio_str = f"{pos_count}+/{neg_count}-"           # Ratio r√®gles positives/n√©gatives
        print(f"{status} {img_name:25} | {true_label:6} ‚Üí {predicted:6} | Score: {score:+.3f} | Conf: {confidence:.3f} | {ratio_str:7} | {advanced_count} r√®gles avanc√©es")
        
        # √âvaluation de la pr√©diction et collecte des erreurs
        if predicted == true_label:
            correct += 1  # Compteur des pr√©dictions correctes
        else:
            # Analyse d√©taill√©e des erreurs pour am√©lioration future
            errors_analysis.append({
                'image': img_name,
                'expected': true_label,
                'predicted': predicted,
                'score': score,
                'confidence': confidence,
                'active_rules': result['details']['active_rules'],  # R√®gles qui ont influenc√© l'erreur
                'advanced_rules': advanced_rules                   # R√®gles avanc√©es impliqu√©es
            })
            
        # Debug d√©taill√© pour les premi√®res images (optionnel)
        if show_details and i < 3:
            print(f"    Rules actives: {result['details']['active_rules']}")
            print(f"    R√®gles avanc√©es: {advanced_rules}")
            print(f"    Score brut: {result['details']['raw_score']:.2f}")
    
    # === CALCUL ET AFFICHAGE DES M√âTRIQUES FINALES ===
    
    print(f"\n=== R√âSULTATS FINAUX (MODE {precision_mode}) ===")
    print(f"Pr√©cision globale: {correct}/{total} = {correct/total:.2%}")
    print(f"R√©partition: {predictions_count}")
    
    # Plus besoin de calculer la pr√©cision sans les "inconnu" puisqu'il n'y en a plus
    # Toutes les pr√©dictions sont maintenant d√©finitives
    
    # Statistiques des scores pour validation de la distribution
    if scores:
        print(f"\nStatistiques des scores:")
        print(f"  Moyenne: {sum(scores)/len(scores):+.3f}")        # Biais vers plein (+) ou vide (-)
        print(f"  Min: {min(scores):+.3f}, Max: {max(scores):+.3f}")  # √âtendue des scores
        print(f"  Confiance moyenne: {sum(confidences)/len(confidences):.3f}")  # Fiabilit√© g√©n√©rale
        
    # Analyse des ratios de r√®gles positives/n√©gatives
    print(f"\nAnalyse des ratios r√®gles positives/n√©gatives:")
    for class_name in ["plein", "vide"]:  # Plus d'"inconnu"
        if positive_rules_avg[class_name]:
            pos_avg = sum(positive_rules_avg[class_name]) / len(positive_rules_avg[class_name])
            neg_avg = sum(negative_rules_avg[class_name]) / len(negative_rules_avg[class_name])
            print(f"  {class_name}: {pos_avg:.1f}+ / {neg_avg:.1f}- (ratio: {pos_avg/max(1, neg_avg):.2f})")
    
    # Analyse des erreurs pour identifier les am√©liorations possibles
    if errors_analysis:
        print(f"\nAnalyse des erreurs ({len(errors_analysis)} erreurs):")
        error_rules = []  # Collecte des r√®gles impliqu√©es dans les erreurs
        
        # Affichage des erreurs les plus repr√©sentatives avec ratio positif/n√©gatif
        for err in errors_analysis[:5]:  # Limiter √† 5 pour lisibilit√©
            pos_count = sum(1 for rule in err['active_rules'] if not rule.startswith(('area_ratio_low', 'hue_std_low', 
                                                                                     'contrast_iqr_low', 'edge_density_high', 
                                                                                     'mean_brightness_high', 'texture_entropy_low',
                                                                                     'color_complexity_low', 'brightness_variance_low')))
            neg_count = len(err['active_rules']) - pos_count
            print(f"  {err['image']:20} {err['expected']} ‚Üí {err['predicted']} (score: {err['score']:+.3f}, ratio: {pos_count}+/{neg_count}-)")
            error_rules.extend(err['active_rules'])  # Accumuler les r√®gles probl√©matiques
        
        # Identification des r√®gles les plus souvent impliqu√©es dans les erreurs
        # UTILIT√â : Permet d'identifier les r√®gles √† revoir/ajuster
        if error_rules:
            rule_counter = Counter(error_rules)
            print(f"\nR√®gles les plus impliqu√©es dans les erreurs:")
            for rule, count in rule_counter.most_common(5):
                # D√©terminer si c'est une r√®gle positive ou n√©gative
                rule_type = "+" if not rule.startswith(('area_ratio_low', 'hue_std_low', 'contrast_iqr_low', 
                                                       'edge_density_high', 'mean_brightness_high', 'texture_entropy_low',
                                                       'color_complexity_low', 'brightness_variance_low', 'spatial_frequency_low',
                                                       'fill_ratio_advanced_low')) else "-"
                print(f"  {rule} ({rule_type}): {count} fois")
    
    # === ANALYSE DES R√àGLES AVANC√âES ===
    if advanced_rules_usage:
        print(f"\nAnalyse des r√®gles avanc√©es:")
        print(f"  Utilisation totale des r√®gles avanc√©es: {sum(advanced_rules_usage.values())} fois")
        
        # Top 5 des r√®gles avanc√©es les plus utilis√©es
        print(f"\nTop 5 des r√®gles avanc√©es les plus actives:")
        for rule, count in advanced_rules_usage.most_common(5):
            success_rate = advanced_rules_success.get(rule, 0) / count if count > 0 else 0
            print(f"  {rule}: {count} fois (taux de succ√®s: {success_rate:.1%})")
        
        # R√®gles avanc√©es avec le meilleur taux de succ√®s
        print(f"\nR√®gles avanc√©es les plus efficaces (min. 5 utilisations):")
        for rule, count in advanced_rules_usage.items():
            if count >= 5:  # Au moins 5 utilisations pour √™tre significatif
                success_rate = advanced_rules_success.get(rule, 0) / count
                if success_rate > 0.7:  # Afficher seulement les r√®gles √† succ√®s √©lev√©
                    print(f"  {rule}: {success_rate:.1%} de succ√®s ({advanced_rules_success.get(rule, 0)}/{count})")
    
    return classifier, correct/total


# === POINT D'ENTR√âE PRINCIPAL ===
if __name__ == "__main__":
    """
    Ex√©cution directe du module pour test rapide
    
    UTILISATION :
    - python backend/services/classifier.py
    - Ou depuis la racine : python -c "from backend.services.classifier import test_classifier; test_classifier()"
    
    OPTIONS:
    - show_details=True: Afficher le d√©tail des r√®gles
    - high_precision=True: Utiliser le mode haute pr√©cision (plus strict)
    """
    print("Test du classifier\n")
    
    # Test en mode standard
    print("\n\n=== MODE STANDARD ===")
    classifier_std, accuracy_std = test_classifier(show_details=True, high_precision=True)
    print(f"\nüéØ Pr√©cision mode standard: {accuracy_std:.2%}..")
    
    # Test en mode haute pr√©cision
    #print("\n\n=== MODE HAUTE PR√âCISION ===")
    #classifier_hp, accuracy_hp = test_classifier(show_details=True, high_precision=True)
    
    # Comparaison des r√©sultats
    #print("\n\n=== COMPARAISON DES MODES ===")
    #print(f"üéØ Mode standard:        {accuracy_std:.2%}")
    #print(f"üéØ Mode haute pr√©cision: {accuracy_hp:.2%}")
    
    # PROCHAINES √âTAPES sugg√©r√©es selon l'accuracy du meilleur mode:
    #best_accuracy = max(accuracy_std, accuracy_hp)
    #print(best_accuracy)